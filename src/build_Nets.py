# -*- coding: utf8 -*-import mxnet as mxdef build_lenet():    data = mx.symbol.Variable('data')    label = mx.symbol.Variable('label')    # first conv layer    conv1 = mx.sym.Convolution(data=data, kernel=(5, 5), num_filter=20)    tanh1 = mx.sym.Activation(data=conv1, act_type="tanh")    pool1 = mx.sym.Pooling(data=tanh1, pool_type="max", kernel=(2, 2), stride=(2, 2))    # second conv layer    conv2 = mx.sym.Convolution(data=pool1, kernel=(5, 5), num_filter=50)    tanh2 = mx.sym.Activation(data=conv2, act_type="tanh")    pool2 = mx.sym.Pooling(data=tanh2, pool_type="max", kernel=(2, 2), stride=(2, 2))    # first fullc layer    flatten = mx.sym.Flatten(data=pool2)    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)    tanh3 = mx.sym.Activation(data=fc1, act_type="tanh")    # second fullc    fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=1)    # softmax loss    # lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')    lenet = mx.sym.LinearRegressionOutput(data=fc2, label=label, name='linear_reg')    return lenet